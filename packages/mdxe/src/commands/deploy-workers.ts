/**
 * Deploy Workers Command
 *
 * Deploy compiled MDX to Cloudflare Workers using worker_loaders.
 * This enables dynamic loading of MDX modules as isolated workers.
 *
 * @packageDocumentation
 */

import { existsSync, readFileSync, readdirSync, statSync, mkdirSync, writeFileSync } from 'node:fs'
import { join, relative, extname, basename, dirname } from 'node:path'
import { createHash } from 'node:crypto'
import { parse } from 'mdxld'

// Local implementation of worker code generation to avoid circular dependency
// This mirrors the functionality from @mdxe/workers/generate.ts

/**
 * Options for generating worker code
 */
interface GenerateWorkerOptions {
  /** Module code to embed (ES6 or CommonJS) */
  module?: string
  /** Script code to execute */
  script?: string
}

/**
 * Extract export names from module code
 */
function getExportNames(moduleCode: string): string {
  const names = new Set<string>()

  // Match exports.name = ...
  const dotPattern = /exports\.(\w+)\s*=/g
  let match
  while ((match = dotPattern.exec(moduleCode)) !== null) {
    if (match[1]) names.add(match[1])
  }

  // Match export const name = ... or export let name = ... or export var name = ...
  const esConstPattern = /export\s+(?:const|let|var)\s+(\w+)\s*=/g
  while ((match = esConstPattern.exec(moduleCode)) !== null) {
    if (match[1]) names.add(match[1])
  }

  // Match export function name(...)
  const esFunctionPattern = /export\s+(?:async\s+)?function\*?\s+(\w+)\s*\(/g
  while ((match = esFunctionPattern.exec(moduleCode)) !== null) {
    if (match[1]) names.add(match[1])
  }

  // Match export class name
  const esClassPattern = /export\s+class\s+(\w+)/g
  while ((match = esClassPattern.exec(moduleCode)) !== null) {
    if (match[1]) names.add(match[1])
  }

  return Array.from(names).join(', ') || '_unused'
}

/**
 * Transform module code to work in sandbox
 */
function transformModuleCode(moduleCode: string): string {
  let code = moduleCode

  // Transform: export const foo = ... -> const foo = exports.foo = ...
  code = code.replace(/export\s+(const|let|var)\s+(\w+)\s*=/g, '$1 $2 = exports.$2 =')

  // Transform: export function foo(...) -> function foo(...)
  code = code.replace(/export\s+(async\s+)?function(\*?)\s+(\w+)/g, '$1function$2 $3')

  // Add exports for functions after their definition
  const funcPattern = /export\s+(?:async\s+)?function\*?\s+(\w+)/g
  let funcMatch
  while ((funcMatch = funcPattern.exec(moduleCode)) !== null) {
    if (funcMatch[1]) {
      code += `\nexports.${funcMatch[1]} = ${funcMatch[1]};`
    }
  }

  // Transform: export class Foo -> class Foo
  code = code.replace(/export\s+class\s+(\w+)/g, 'class $1')
  const classPattern = /export\s+class\s+(\w+)/g
  let classMatch
  while ((classMatch = classPattern.exec(moduleCode)) !== null) {
    if (classMatch[1]) {
      code += `\nexports.${classMatch[1]} = ${classMatch[1]};`
    }
  }

  return code
}

/**
 * Wrap script to auto-return the last expression
 */
function wrapScriptForReturn(script: string): string {
  const trimmed = script.trim()
  if (!trimmed) return script

  if (/\breturn\b/.test(trimmed)) return script
  if (/^\s*throw\b/.test(trimmed)) return script

  const withoutTrailingSemi = trimmed.replace(/;?\s*$/, '')
  const isSingleLine = !withoutTrailingSemi.includes('\n')

  const startsWithKeyword =
    /^\s*(const|let|var|if|for|while|switch|try|class|function|async\s+function)\b/.test(
      withoutTrailingSemi
    )

  if (isSingleLine && !startsWithKeyword) {
    return `return ${withoutTrailingSemi}`
  }

  const lines = trimmed.split('\n')
  const lastLineRaw = lines[lines.length - 1]
  if (!lastLineRaw) return script
  const lastLine = lastLineRaw.trim()

  if (
    lastLine &&
    !/^\s*(const|let|var|if|for|while|switch|try|class|function|return|throw)\b/.test(lastLine)
  ) {
    lines[lines.length - 1] = `return ${lastLine.replace(/;?\s*$/, '')}`
    return lines.join('\n')
  }

  return script
}

/**
 * Generate worker code for MDX evaluation
 */
function generateWorkerCode(options: GenerateWorkerOptions = {}): string {
  const { module: rawModule = '', script: rawScript = '' } = options

  const module = rawModule ? transformModuleCode(rawModule) : ''
  const script = rawScript ? wrapScriptForReturn(rawScript) : ''
  const exportNames = getExportNames(rawModule)

  return `
// MDX Worker Entry Point
// Generated by mdxe deploy workers

const logs = [];

// Capture console output
const originalConsole = { ...console };
const captureConsole = (level) => (...args) => {
  logs.push({
    level,
    message: args.map(a => typeof a === 'object' ? JSON.stringify(a) : String(a)).join(' '),
    timestamp: Date.now()
  });
  originalConsole[level](...args);
};
console.log = captureConsole('log');
console.warn = captureConsole('warn');
console.error = captureConsole('error');
console.info = captureConsole('info');
console.debug = captureConsole('debug');

// Module exports object
const exports = {};

${
  module
    ? `
// Execute module code
try {
${module}
} catch (e) {
  console.error('Module error:', e.message);
}
`
    : '// No module code provided'
}

// Expose all exports as top-level variables
${rawModule ? `const { ${exportNames} } = exports;`.trim() : ''}

// Worker entry point
export default {
  async fetch(request, env) {
    const url = new URL(request.url);

    // Route: GET / - Return info about exports
    if (request.method === 'GET' && url.pathname === '/') {
      return Response.json({
        exports: Object.keys(exports),
        execute: '/execute'
      });
    }

    // Route: GET /:name - Access exports
    if (request.method === 'GET' && url.pathname !== '/execute') {
      const name = url.pathname.slice(1);
      const value = exports[name];

      if (!(name in exports)) {
        return Response.json({ error: \`Export "\${name}" not found\` }, { status: 404 });
      }

      if (typeof value !== 'function') {
        return Response.json({ result: value });
      }

      try {
        const args = [];
        const argsParam = url.searchParams.get('args');
        if (argsParam) {
          try {
            const parsed = JSON.parse(argsParam);
            if (Array.isArray(parsed)) {
              args.push(...parsed);
            } else {
              args.push(parsed);
            }
          } catch {
            args.push(argsParam);
          }
        }
        const result = await value(...args);
        return Response.json({ result });
      } catch (e) {
        return Response.json({ error: e.message }, { status: 500 });
      }
    }

    // Route: /execute - Run scripts
    let scriptResult = undefined;
    let scriptError = null;

    ${
      script
        ? `
    try {
      scriptResult = await (async () => {
${script}
      })();
    } catch (e) {
      console.error('Script error:', e.message);
      scriptError = e.message;
    }
    `
        : '// No script code provided'
    }

    return Response.json({
      success: scriptError === null,
      value: scriptResult,
      logs,
      error: scriptError || undefined,
    });
  }
};
`
}

/**
 * Compiled module information
 */
export interface CompiledWorkerModule {
  /** Module name (derived from file path) */
  name: string
  /** Generated worker code */
  code: string
  /** Frontmatter data */
  data: Record<string, unknown>
  /** Exported function/variable names */
  exports: string[]
  /** Content hash for caching */
  hash: string
  /** Original file path */
  sourcePath: string
  /** Compilation error (if any) */
  error?: string
}

/**
 * Compilation result
 */
export interface CompileResult {
  success: boolean
  modules: CompiledWorkerModule[]
  contentHash: string
  error?: string
  logs: string[]
  duration: number
}

/**
 * Wrangler configuration with worker_loaders
 */
export interface WorkersWranglerConfig {
  name: string
  compatibility_date: string
  compatibility_flags?: string[]
  main?: string
  worker_loaders?: Array<{
    binding: string
    format?: string
  }>
  vars?: Record<string, string>
}

/**
 * Deployment result
 */
export interface WorkerDeployResult {
  success: boolean
  url?: string
  workerId?: string
  workerIds?: string[]
  contentHash?: string
  error?: string
  logs: string[]
  duration: number
}

/**
 * Deployment options
 */
export interface WorkerDeployOptions {
  projectDir: string
  name: string
  accountId?: string
  apiToken?: string
  useContentHash?: boolean
  compatibilityDate?: string
  compatibilityFlags?: string[]
  dryRun?: boolean
  verbose?: boolean
}

/**
 * Simple hash function for content
 */
function hashContent(content: string): string {
  return createHash('sha256')
    .update(content)
    .digest('hex')
    .slice(0, 16)
}

/**
 * Generate a worker ID from content, optionally with a version suffix
 */
export function generateWorkerId(content: string, version?: string): string {
  const hash = hashContent(content)
  return version ? `${hash}-${version}` : hash
}

/**
 * Find all MDX files recursively in a directory
 */
function findMdxFiles(dir: string, baseDir: string = dir): string[] {
  const files: string[] = []

  if (!existsSync(dir)) {
    return files
  }

  const entries = readdirSync(dir)

  for (const entry of entries) {
    const fullPath = join(dir, entry)
    const stat = statSync(fullPath)

    if (stat.isDirectory() && !entry.startsWith('.') && entry !== 'node_modules' && entry !== 'dist') {
      files.push(...findMdxFiles(fullPath, baseDir))
    } else if (stat.isFile() && (entry.endsWith('.mdx') || entry.endsWith('.md'))) {
      const relativePath = relative(baseDir, fullPath)
      files.push(relativePath)
    }
  }

  return files
}

/**
 * Convert file path to module name
 */
function fileToModuleName(filePath: string): string {
  return filePath
    .replace(/\\/g, '/')
    .replace(/\.mdx?$/, '')
    .replace(/\/index$/, '')
    .replace(/\/README$/i, '')
}

/**
 * Extract code blocks from MDX content
 */
function extractCodeBlocks(content: string): { code: string; language: string }[] {
  const blocks: { code: string; language: string }[] = []
  const codeBlockRegex = /```(?:ts|typescript|js|javascript|tsx|jsx)(?:\s+\w+)?\n([\s\S]*?)```/g

  let match
  while ((match = codeBlockRegex.exec(content)) !== null) {
    blocks.push({
      code: match[1] || '',
      language: 'typescript',
    })
  }

  return blocks
}

/**
 * Extract exported function names from code
 */
function extractExports(code: string): string[] {
  const exports: string[] = []

  // Match export const/let/var/function/class
  const exportMatches = code.matchAll(/export\s+(?:const|let|var|function|async\s+function|class)\s+(\w+)/g)
  for (const match of exportMatches) {
    if (match[1]) exports.push(match[1])
  }

  // Match export { ... }
  const namedExportMatches = code.matchAll(/export\s*\{\s*([^}]+)\s*\}/g)
  for (const match of namedExportMatches) {
    if (match[1]) {
      const names = match[1].split(',').map(n => n.trim().split(/\s+as\s+/).pop()?.trim()).filter(Boolean)
      exports.push(...(names as string[]))
    }
  }

  return exports
}

/**
 * Compile MDX files to worker modules
 */
export async function compileForWorkers(
  projectDir: string,
  options: { verbose?: boolean } = {}
): Promise<CompileResult> {
  const startTime = Date.now()
  const logs: string[] = []
  const modules: CompiledWorkerModule[] = []

  try {
    // Find all MDX files
    const mdxFiles = findMdxFiles(projectDir)

    if (mdxFiles.length === 0) {
      return {
        success: false,
        modules: [],
        contentHash: '',
        error: 'No MDX files found in project directory',
        logs,
        duration: Date.now() - startTime,
      }
    }

    logs.push(`Found ${mdxFiles.length} MDX file(s)`)

    // Process each file
    for (const file of mdxFiles) {
      const filePath = join(projectDir, file)
      const moduleName = fileToModuleName(file)

      if (options.verbose) {
        logs.push(`Processing: ${file} -> ${moduleName}`)
      }

      try {
        const content = readFileSync(filePath, 'utf-8')
        const doc = parse(content) as {
          id?: string
          type?: string | string[]
          context?: string | string[] | Record<string, unknown>
          data: Record<string, unknown>
          content: string
        }

        // Extract code blocks from content
        const codeBlocks = extractCodeBlocks(doc.content)

        // Combine all code blocks
        const allCode = codeBlocks.map(b => b.code).join('\n\n')

        // Extract exports from combined code
        const exports = extractExports(allCode)

        // Generate worker code from the extracted module code
        const workerCode = generateWorkerCode({
          module: allCode,
          script: '', // No additional script
        })

        // Calculate hash
        const hash = hashContent(content)

        // Merge root-level LD properties back into data for convenience
        const moduleData: Record<string, unknown> = { ...doc.data }
        if (doc.id) moduleData.$id = doc.id
        if (doc.type) moduleData.$type = doc.type
        if (doc.context) moduleData.$context = doc.context

        modules.push({
          name: moduleName,
          code: workerCode,
          data: moduleData,
          exports,
          hash,
          sourcePath: file,
        })

        if (options.verbose && exports.length > 0) {
          logs.push(`  Exports: ${exports.join(', ')}`)
        }
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error'
        logs.push(`Error compiling ${file}: ${errorMessage}`)

        modules.push({
          name: moduleName,
          code: '',
          data: {},
          exports: [],
          hash: '',
          sourcePath: file,
          error: errorMessage,
        })
      }
    }

    // Calculate overall content hash
    const allHashes = modules.map(m => m.hash).sort().join('')
    const contentHash = hashContent(allHashes)

    logs.push(`Compiled ${modules.filter(m => !m.error).length}/${modules.length} module(s)`)

    return {
      success: true,
      modules,
      contentHash,
      logs,
      duration: Date.now() - startTime,
    }
  } catch (error) {
    return {
      success: false,
      modules: [],
      contentHash: '',
      error: error instanceof Error ? error.message : 'Unknown error',
      logs,
      duration: Date.now() - startTime,
    }
  }
}

/**
 * Generate wrangler configuration with worker_loaders binding
 */
export function generateWorkersConfig(options: {
  name: string
  modules: Array<{ name: string; code: string; hash: string }>
  compatibilityDate?: string
  compatibilityFlags?: string[]
  env?: Record<string, string>
}): WorkersWranglerConfig {
  const config: WorkersWranglerConfig = {
    name: options.name,
    compatibility_date: options.compatibilityDate || new Date().toISOString().split('T')[0]!,
  }

  if (options.compatibilityFlags?.length) {
    config.compatibility_flags = options.compatibilityFlags
  }

  // Add worker_loaders binding for dynamic module loading
  config.worker_loaders = [
    {
      binding: 'MDX_LOADER',
      format: 'esm',
    },
  ]

  // Add environment variables
  if (options.env && Object.keys(options.env).length > 0) {
    config.vars = options.env
  }

  return config
}

/**
 * Generate the orchestrator worker that loads MDX modules dynamically
 */
function generateOrchestratorWorker(modules: CompiledWorkerModule[]): string {
  // Generate module manifest
  const manifest = modules
    .filter(m => !m.error)
    .map(m => ({
      name: m.name,
      hash: m.hash,
      exports: m.exports,
      data: m.data,
    }))

  return `/**
 * MDX Worker Orchestrator
 * Generated by mdxe deploy workers
 *
 * This worker uses the worker_loaders binding to dynamically load
 * compiled MDX modules based on the request path.
 */

// Module manifest - maps paths to module metadata
const MODULES = ${JSON.stringify(manifest, null, 2)};

// Module code cache - keyed by hash
const MODULE_CODE = new Map();

export default {
  async fetch(request, env, ctx) {
    const url = new URL(request.url);
    const path = url.pathname;

    // Health check
    if (path === '/health' || path === '/_health') {
      return Response.json({ status: 'ok', modules: MODULES.length });
    }

    // List modules
    if (path === '/' || path === '/_modules') {
      return Response.json({
        modules: MODULES.map(m => ({
          name: m.name,
          exports: m.exports,
          data: m.data,
        })),
      });
    }

    // Find matching module
    const modulePath = path.replace(/^\\//, '').replace(/\\/$/, '') || 'index';
    const moduleInfo = MODULES.find(m => m.name === modulePath);

    if (!moduleInfo) {
      return Response.json({ error: 'Module not found', path: modulePath }, { status: 404 });
    }

    // Load the module using worker_loaders
    try {
      const loader = env.MDX_LOADER;

      // Get or create the worker for this module
      const worker = loader.get(moduleInfo.hash, async () => {
        // Return the module configuration
        // The code is embedded in the module bundle
        return {
          mainModule: 'worker.js',
          modules: {
            'worker.js': MODULE_CODE.get(moduleInfo.hash),
          },
          compatibilityDate: '${new Date().toISOString().split('T')[0]}',
        };
      });

      // Forward the request to the loaded worker
      const entrypoint = worker.getEntrypoint();
      return entrypoint.fetch(request);
    } catch (error) {
      return Response.json({
        error: 'Failed to load module',
        message: error.message,
      }, { status: 500 });
    }
  }
};
`
}

/**
 * Deploy MDX files as workers using worker_loaders
 */
export async function deployWorkers(options: WorkerDeployOptions): Promise<WorkerDeployResult> {
  const startTime = Date.now()
  const logs: string[] = []

  // Validate project directory
  if (!existsSync(options.projectDir)) {
    return {
      success: false,
      error: `Project directory does not exist: ${options.projectDir}`,
      logs,
      duration: Date.now() - startTime,
    }
  }

  logs.push(`Deploying from ${options.projectDir}`)

  // Compile MDX files
  const compileResult = await compileForWorkers(options.projectDir, {
    verbose: options.verbose,
  })

  logs.push(...compileResult.logs)

  if (!compileResult.success) {
    return {
      success: false,
      error: compileResult.error || 'Compilation failed',
      logs,
      duration: Date.now() - startTime,
    }
  }

  const validModules = compileResult.modules.filter(m => !m.error)

  if (validModules.length === 0) {
    return {
      success: false,
      error: 'No MDX files found or all files failed to compile',
      logs,
      duration: Date.now() - startTime,
    }
  }

  // Generate wrangler config
  const config = generateWorkersConfig({
    name: options.name,
    modules: validModules,
    compatibilityDate: options.compatibilityDate,
    compatibilityFlags: options.compatibilityFlags,
  })

  logs.push(`Generated wrangler config for ${validModules.length} module(s)`)

  // Generate worker IDs
  const workerIds = validModules.map(m =>
    options.useContentHash
      ? generateWorkerId(m.code)
      : `${options.name}-${m.name.replace(/\//g, '-')}`
  )

  if (options.dryRun) {
    logs.push('[DRY RUN] Would deploy the following workers:')
    for (let i = 0; i < validModules.length; i++) {
      logs.push(`  - ${validModules[i]!.name} (${workerIds[i]})`)
    }
    logs.push(`[DRY RUN] Content hash: ${compileResult.contentHash}`)

    return {
      success: true,
      workerIds,
      contentHash: compileResult.contentHash,
      logs,
      duration: Date.now() - startTime,
    }
  }

  // In non-dry-run mode, we would call the Cloudflare API
  // For now, we generate the deployment artifacts

  const outDir = join(options.projectDir, '.mdxe-workers')
  mkdirSync(outDir, { recursive: true })

  // Write wrangler config
  writeFileSync(
    join(outDir, 'wrangler.json'),
    JSON.stringify(config, null, 2)
  )

  // Write orchestrator worker
  const orchestratorCode = generateOrchestratorWorker(validModules)
  writeFileSync(join(outDir, 'worker.js'), orchestratorCode)

  // Write module code files
  const modulesDir = join(outDir, 'modules')
  mkdirSync(modulesDir, { recursive: true })

  for (const module of validModules) {
    const moduleDir = join(modulesDir, dirname(module.name))
    if (!existsSync(moduleDir)) {
      mkdirSync(moduleDir, { recursive: true })
    }
    writeFileSync(
      join(modulesDir, `${module.name}.js`),
      module.code
    )
  }

  // Write module manifest
  writeFileSync(
    join(outDir, 'manifest.json'),
    JSON.stringify({
      name: options.name,
      modules: validModules.map(m => ({
        name: m.name,
        hash: m.hash,
        exports: m.exports,
        data: m.data,
        workerId: options.useContentHash ? generateWorkerId(m.code) : `${options.name}-${m.name.replace(/\//g, '-')}`,
      })),
      contentHash: compileResult.contentHash,
      built: new Date().toISOString(),
    }, null, 2)
  )

  logs.push(`Generated deployment artifacts in ${outDir}`)
  logs.push(`To deploy, run: npx wrangler deploy -c ${join(outDir, 'wrangler.json')}`)

  return {
    success: true,
    workerIds,
    contentHash: compileResult.contentHash,
    logs,
    duration: Date.now() - startTime,
  }
}
